{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Dropout,BatchNormalization,Activation,ZeroPadding2D,AveragePooling2D,MaxPooling2D,Add,AveragePooling2D,Flatten,Dense,Input\n",
    "from keras.utils import to_categorical\n",
    "from keras.initializers import glorot_uniform,glorot_normal\n",
    "from keras.optimizers import Adadelta\n",
    "from keras import backend as k\n",
    "from keras.engine.input_layer import Input\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "\n",
    "#Set to mini batch\n",
    "batch_size = 128\n",
    "#the number of classes we want to classify 0 --- 9\n",
    "num_classes =10\n",
    "#the size of the image in the mnist dataset\n",
    "img_rows,img_columns = 28 ,28\n",
    "#load the data to a trainning and testing\n",
    "(x_train_data,y_train),(x_test_data,y_test) = mnist.load_data()\n",
    "#changing the shapes to fit as we are using tensorflow as a backend\n",
    "x_train = x_train_data.reshape(x_train_data.shape[0],img_rows,img_columns,1)\n",
    "x_test = x_test_data.reshape(x_test_data.shape[0],img_rows,img_columns,1)\n",
    "input_shape = (img_rows,img_columns,1)\n",
    "\n",
    "#change the type for calcuations\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "#normilize the values\n",
    "x_train /=255\n",
    "x_test /=255\n",
    "\n",
    "#convert the class vector to a binary matrix \n",
    "#the values a represnted as 0 0 0 0 0 0 0 0 0 0 \n",
    "# and there will be one on the correct class\n",
    "y_train = to_categorical(y_train,num_classes)\n",
    "y_test = to_categorical(y_test,num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_block(X,f,filters,stage,block,s = 2):\n",
    "\n",
    "    #define the name basis\n",
    "    conv_name_base = \"res\" + str(stage)+block + \"_branch\"\n",
    "    #batch normailization name basis\n",
    "    bn_name_base = \"bn\" + str(stage)+block+ \"_branch\"\n",
    "    #get the filters\n",
    "    f1,f2,f3 = filters\n",
    "    #save the shortcut value\n",
    "    x_shortcut = X\n",
    "    #creat the main path\n",
    "    #create the first layer\n",
    "    X = Conv2D(f1,kernel_size = (1,1),strides = (s,s),name = conv_name_base +'2a',padding= 'valid'\n",
    "               ,kernel_initializer=glorot_normal(seed = 0))(X)\n",
    "    X = BatchNormalization(axis = 3,name = bn_name_base +'2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    #create the second layer\n",
    "    X = Conv2D(f2,kernel_size = (f,f),strides = (1,1),name = conv_name_base +'2b',padding= 'same'\n",
    "               ,kernel_initializer=glorot_normal(seed = 0))(X)\n",
    "    X = BatchNormalization(axis = 3,name = bn_name_base +'2b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    #create the Third layer\n",
    "    X = Conv2D(f3,kernel_size = (1,1),strides = (1,1),name = conv_name_base +'2c',padding= 'valid'\n",
    "               ,kernel_initializer=glorot_normal(seed = 0))(X)\n",
    "    X = BatchNormalization(axis = 3,name = bn_name_base +'2c')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    #create the shortcut path\n",
    "    #the filter size is the same as the last one so they could match\n",
    "    x_shortcut = Conv2D(f3,kernel_size = (1,1),strides = (s,s),name = conv_name_base +'1',padding= 'valid'\n",
    "               ,kernel_initializer=glorot_normal(seed = 0))(x_shortcut)\n",
    "    x_shortcut = BatchNormalization(axis = 3,name = bn_name_base +'1')(x_shortcut)\n",
    "    \n",
    "    X = Add()([X,x_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_Block(X,f,filters,stage,block):\n",
    "    \n",
    "    #define the name basis\n",
    "    conv_name_base = \"res\" + str(stage)+block + \"_branch\"\n",
    "    #batch normailization name basis\n",
    "    bn_name_base = \"bn\" + str(stage)+block+ \"_branch\"\n",
    "    \n",
    "    #get the filters\n",
    "    f1,f2,f3 = filters\n",
    "    #get the shorcut pass\n",
    "    x_shortcut = X\n",
    "    \n",
    "    #create the main path which will hold the conv layers\n",
    "    \n",
    "    #First layer main path\n",
    "    X = Conv2D(f1,kernel_size = (1,1),strides = (1,1),padding='valid',name = conv_name_base + '2a'\n",
    "               ,kernel_initializer=glorot_normal(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3,name = bn_name_base+'2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    #second layer main path\n",
    "    X = Conv2D(f2,kernel_size = (f,f),strides=(1,1),padding='same',name = conv_name_base + '2b'\n",
    "               ,kernel_initializer = glorot_normal(seed = 0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "               \n",
    "    \n",
    "    #Thrid layer in main path\n",
    "    X = Conv2D(f3,kernel_size = (1,1),strides = (1,1),padding= 'valid',name = conv_name_base +'2c',\n",
    "              kernel_initializer = glorot_normal(seed = 0))(X)               \n",
    "    X = BatchNormalization(axis = 3,name = bn_name_base + '2c')(X)\n",
    "    #adding the shortcut path\n",
    "    X = Add()([X ,x_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "               \n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pixels = x_test_data[1]\n",
    "pixels = np.array(pixels,'uint8')\n",
    "print(pixels.shape)\n",
    "pixels  = pixels.reshape(28,28)\n",
    "plt.imshow(pixels,cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_input = Input(input_shape)\n",
    "\n",
    "\n",
    "X = ZeroPadding2D(padding = (3,3))(model_input)\n",
    "\n",
    "#stage 1\n",
    "X = Conv2D(filters = 32,kernel_size = (7,7),strides= (2,2),name='conv1'\n",
    "               ,kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "X = BatchNormalization(axis = 3,name= 'bn_conv1')(X)\n",
    "X = Activation('relu')(X)\n",
    "X = MaxPooling2D((3,3),strides=(2,2))(X)\n",
    "\n",
    "X = convolutional_block(X = X,f = 3, filters =[32,32,64],stage = 2,block = 'a',s = 2)\n",
    "\n",
    "X = Flatten()(X)\n",
    "\n",
    "X = Dense(num_classes,activation='softmax',name = 'fc' + str(num_classes)\n",
    "              ,kernel_initializer = glorot_uniform(seed = 0))(X)\n",
    "\n",
    "model_object = Model(inputs = model_input,outputs = X,name ='TestNet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_12 (InputLayer)           (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_12 (ZeroPadding2 (None, 34, 34, 1)    0           input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 14, 14, 32)   1600        zero_padding2d_12[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 14, 14, 32)   128         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 14, 14, 32)   0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling2D) (None, 6, 6, 32)     0           activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 3, 3, 32)     1056        max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 3, 3, 32)     128         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 3, 3, 32)     0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 3, 3, 32)     9248        activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 3, 3, 32)     128         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 3, 3, 32)     0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 3, 3, 64)     2112        activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 3, 3, 64)     256         res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 3, 3, 64)     2112        max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 3, 3, 64)     0           bn2a_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 3, 3, 64)     256         res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 3, 3, 64)     0           activation_84[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 3, 3, 64)     0           add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_11 (Flatten)            (None, 576)          0           activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "fc10 (Dense)                    (None, 10)           5770        flatten_11[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 22,794\n",
      "Trainable params: 22,346\n",
      "Non-trainable params: 448\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_object.summary()#3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup the model for training\n",
    "model_object.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = Adadelta(),\n",
    "              #We can specify more metrics that we want to monitor\n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "60000/60000 [==============================] - 38s 640us/step - loss: 0.2018 - acc: 0.9410 - val_loss: 0.0883 - val_acc: 0.9708\n",
      "Epoch 2/15\n",
      "60000/60000 [==============================] - 36s 593us/step - loss: 0.0666 - acc: 0.9796 - val_loss: 0.0677 - val_acc: 0.9775\n",
      "Epoch 3/15\n",
      "60000/60000 [==============================] - 35s 589us/step - loss: 0.0488 - acc: 0.9843 - val_loss: 0.0463 - val_acc: 0.9850\n",
      "Epoch 4/15\n",
      "60000/60000 [==============================] - 35s 590us/step - loss: 0.0374 - acc: 0.9882 - val_loss: 0.0546 - val_acc: 0.9824\n",
      "Epoch 5/15\n",
      "60000/60000 [==============================] - 35s 589us/step - loss: 0.0300 - acc: 0.9905 - val_loss: 0.0488 - val_acc: 0.9855\n",
      "Epoch 6/15\n",
      "60000/60000 [==============================] - 35s 588us/step - loss: 0.0263 - acc: 0.9919 - val_loss: 0.0469 - val_acc: 0.9857\n",
      "Epoch 7/15\n",
      "60000/60000 [==============================] - 35s 591us/step - loss: 0.0214 - acc: 0.9935 - val_loss: 0.0469 - val_acc: 0.9859\n",
      "Epoch 8/15\n",
      "60000/60000 [==============================] - 35s 589us/step - loss: 0.0180 - acc: 0.9946 - val_loss: 0.0442 - val_acc: 0.9864\n",
      "Epoch 9/15\n",
      "60000/60000 [==============================] - 35s 590us/step - loss: 0.0150 - acc: 0.9954 - val_loss: 0.0445 - val_acc: 0.9868\n",
      "Epoch 10/15\n",
      "60000/60000 [==============================] - 36s 597us/step - loss: 0.0123 - acc: 0.9963 - val_loss: 0.0428 - val_acc: 0.9876\n",
      "Epoch 11/15\n",
      "60000/60000 [==============================] - 35s 590us/step - loss: 0.0103 - acc: 0.9968 - val_loss: 0.0411 - val_acc: 0.9869\n",
      "Epoch 12/15\n",
      "60000/60000 [==============================] - 35s 591us/step - loss: 0.0086 - acc: 0.9979 - val_loss: 0.0481 - val_acc: 0.9873\n",
      "Epoch 13/15\n",
      "60000/60000 [==============================] - 35s 590us/step - loss: 0.0077 - acc: 0.9977 - val_loss: 0.0500 - val_acc: 0.9861\n",
      "Epoch 14/15\n",
      "60000/60000 [==============================] - 35s 589us/step - loss: 0.0064 - acc: 0.9984 - val_loss: 0.0509 - val_acc: 0.9863\n",
      "Epoch 15/15\n",
      "60000/60000 [==============================] - 35s 590us/step - loss: 0.0057 - acc: 0.9986 - val_loss: 0.0494 - val_acc: 0.9869\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd402d7f710>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train the model\n",
    "model_object.fit(x = x_train,y = y_train,\n",
    "          batch_size = batch_size,\n",
    "          epochs = 15,\n",
    "        #this will show is a progress bar put it to 0 so it can remain silent\n",
    "          verbose =1,\n",
    "          validation_data = (x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 3s 276us/step\n"
     ]
    }
   ],
   "source": [
    "#evaluate the model\n",
    "#for more information run model.metrices_names == > ['loss' , 'acc']\n",
    "scores = model_object.evaluate(x = x_test,y=y_test,batch_size = 32,verbose = 1)\n",
    "\n",
    "print(\"The scores :\")\n",
    "scores\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
