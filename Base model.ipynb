{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Activation\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Adadelta\n",
    "from keras import backend as k\n",
    "#Set to mini batch\n",
    "batch_size = 128\n",
    "#the number of classes we want to classify 0 --- 9\n",
    "num_classes =10\n",
    "#the size of the image in the mnist dataset\n",
    "img_rows,img_columns = 28 ,28\n",
    "#load the data to a trainning and testing\n",
    "(x_train,y_train),(x_test,y_test) = mnist.load_data()\n",
    "#changing the shapes to fit as we are using tensorflow as a backend\n",
    "x_train = x_train.reshape(x_train.shape[0],img_rows,img_columns,1)\n",
    "x_test = x_test.reshape(x_test.shape[0],img_rows,img_columns,1)\n",
    "input_shape = (img_rows,img_columns,1)\n",
    "\n",
    "#change the type for calcuations\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "#normilize the values\n",
    "x_train /=255\n",
    "x_test /=255\n",
    "\n",
    "#convert the class vector to a binary matrix \n",
    "#the values a represnted as 0 0 0 0 0 0 0 0 0 0 \n",
    "# and there will be one on the correct class\n",
    "y_train = to_categorical(y_train,num_classes)\n",
    "y_test = to_categorical(y_test,num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the model\n",
    "model =  Sequential()\n",
    "#add a conv2d layer with 32 fiters which will give us 26 26 32 the 32 is the number of channels \n",
    "model.add(Conv2D(32,(3,3),activation = 'relu',input_shape= input_shape))\n",
    "# will give a 24 24 64 channels the image is decrising becuase we are not padding\n",
    "model.add(Conv2D(64,(3,3),activation = 'relu'))\n",
    "#to reduce the size of the image and just keep focusing on the most important features\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "#now we need to flattern the image for use in dense layers\n",
    "model.add(Flatten())\n",
    "#the number of nurons is based on the project the this model is from\n",
    "model.add(Dense(128,activation='relu'))\n",
    "#add a drop out layer so we do not hit overfitting\n",
    "#it will disable hlaf of the nurons in on every input\n",
    "model.add(Dropout(0.5))\n",
    "#the last dense layer for the class classifying\n",
    "model.add(Dense(num_classes))\n",
    "#add the softmax activation to get the values between 0 -- 1\n",
    "model.add(Activation('softmax'))\n",
    "#setup the model for training\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = Adadelta(),\n",
    "              #We can specify more metrics that we want to monitor\n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,199,882\n",
      "Trainable params: 1,199,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#the number of params for a conv2d layer is (filterSize)*No.Filters + No.Filters\n",
    "#                                            (3 * 3) * 32 + 32\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "60000/60000 [==============================] - 345s 6ms/step - loss: 0.0852 - acc: 0.9742 - val_loss: 0.0396 - val_acc: 0.9865\n",
      "Epoch 2/15\n",
      "60000/60000 [==============================] - 429s 7ms/step - loss: 0.0615 - acc: 0.9819 - val_loss: 0.0337 - val_acc: 0.9881\n",
      "Epoch 3/15\n",
      "60000/60000 [==============================] - 428s 7ms/step - loss: 0.0509 - acc: 0.9851 - val_loss: 0.0324 - val_acc: 0.9888\n",
      "Epoch 4/15\n",
      "60000/60000 [==============================] - 388s 6ms/step - loss: 0.0424 - acc: 0.9868 - val_loss: 0.0307 - val_acc: 0.9897\n",
      "Epoch 5/15\n",
      "60000/60000 [==============================] - 132s 2ms/step - loss: 0.0380 - acc: 0.9884 - val_loss: 0.0311 - val_acc: 0.9900\n",
      "Epoch 6/15\n",
      "60000/60000 [==============================] - 132s 2ms/step - loss: 0.0315 - acc: 0.9908 - val_loss: 0.0292 - val_acc: 0.9903\n",
      "Epoch 7/15\n",
      "60000/60000 [==============================] - 132s 2ms/step - loss: 0.0273 - acc: 0.9912 - val_loss: 0.0278 - val_acc: 0.9904\n",
      "Epoch 8/15\n",
      "60000/60000 [==============================] - 131s 2ms/step - loss: 0.0249 - acc: 0.9924 - val_loss: 0.0268 - val_acc: 0.9914\n",
      "Epoch 9/15\n",
      "60000/60000 [==============================] - 131s 2ms/step - loss: 0.0232 - acc: 0.9931 - val_loss: 0.0275 - val_acc: 0.9916\n",
      "Epoch 10/15\n",
      "60000/60000 [==============================] - 132s 2ms/step - loss: 0.0226 - acc: 0.9932 - val_loss: 0.0275 - val_acc: 0.9908\n",
      "Epoch 11/15\n",
      "60000/60000 [==============================] - 131s 2ms/step - loss: 0.0197 - acc: 0.9940 - val_loss: 0.0329 - val_acc: 0.9906\n",
      "Epoch 12/15\n",
      "60000/60000 [==============================] - 131s 2ms/step - loss: 0.0186 - acc: 0.9942 - val_loss: 0.0311 - val_acc: 0.9912\n",
      "Epoch 13/15\n",
      "60000/60000 [==============================] - 131s 2ms/step - loss: 0.0177 - acc: 0.9943 - val_loss: 0.0304 - val_acc: 0.9921\n",
      "Epoch 14/15\n",
      "60000/60000 [==============================] - 131s 2ms/step - loss: 0.0155 - acc: 0.9951 - val_loss: 0.0282 - val_acc: 0.9913\n",
      "Epoch 15/15\n",
      "60000/60000 [==============================] - 131s 2ms/step - loss: 0.0167 - acc: 0.9945 - val_loss: 0.0271 - val_acc: 0.9922\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb5647334e0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train the model\n",
    "model.fit(x = x_train,y = y_train,\n",
    "          batch_size = batch_size,\n",
    "          epochs = 15,\n",
    "        #this will show is a progress bar put it to 0 so it can remain silent\n",
    "          verbose =1,\n",
    "          validation_data = (x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate the model\n",
    "#for more information run model.metrices_names == > ['loss' , 'acc']\n",
    "scores = model.evaluate(x = x_test,y=y_test,batch_size = 32,verbose = 1)\n",
    "\n",
    "print(\"The scroes : \" + scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
